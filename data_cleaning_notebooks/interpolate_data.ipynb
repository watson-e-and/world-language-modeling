{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in missing data\n",
    "Where we have a reasonable guess.\n",
    "\n",
    "Two scenarios\n",
    "1. Fill in missing data from scraping error (ie no Mandarin speakers in China)\n",
    "2. When we have total speaker data for most years, but only L1 and L2 for a few years, we can reasonably assume that the ratio L1/population is somewhat constant, and then calculate L2 from total and guessed L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Scrape Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful maps\n",
    "lang_code_to_name = {\"arz\": \"Egyptian Arabic\", \"ben\": \"Bengali\", \"cmn\": \"Mandarin Chinese\", \"deu\": \"German\", \"eng\": \"English\", \"fra\": \"French\", \"hin\": \"Hindi\", \"ind\": \"Indonesian\", \"jpn\": \"Japanese\", \"por\": \"Portuguese\", \"rus\": \"Russian\", \"spa\": \"Spanish\", \"urd\": \"Urdu\"}\n",
    "\n",
    "name_to_lang_code = {\"Egyptian Arabic\": \"arz\", \"Bengali\": \"ben\", \"Mandarin Chinese\": \"cmn\", \"German\": \"deu\", \"English\": \"eng\", \"French\": \"fra\", \"Hindi\": \"hin\", \"Indonesian\": \"ind\", \"Japanese\": \"jpn\", \"Portuguese\": \"por\", \"Russian\": \"rus\", \"Spanish\": \"spa\", \"Urdu\": \"urd\"}\n",
    "\n",
    "lang_code_to_country = {\"arz\": \"Egypt\", \"ben\": \"Bangladesh\", \"cmn\": \"China\", \"deu\": \"Germany\", \"eng\": \"United Kingdom\", \"fra\": \"France\", \"hin\": \"India\", \"ind\": \"Indonesia\", \"jpn\": \"Japan\", \"por\": \"Portugal\", \"rus\": \"Russian Federation\", \"spa\": \"Spain\", \"urd\": \"Pakistan\"}\n",
    "\n",
    "missing_countries = [\"Egypt\", \"Bangladesh\", \"China\", \"Germany\", \"United Kingdom\", \"France\", \"India\", \"Indonesia\", \"Japan\", \"Portugal\", \"Russian Federation\", \"Spain\", \"Pakistan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_types = [\"total\", \"l1\", \"l2\"]\n",
    "speaker_types = [\"total\"] # freaky, difficult to fix errors are more likely to show up in L1 and L2, we'll use the extrapolation in the next section instead\n",
    "\n",
    "finished_dfs = []\n",
    "for speaker_type in speaker_types:\n",
    "    speakers_df = pd.read_csv(f'../data/cleaned_{speaker_type}_speakers.csv')\n",
    "\n",
    "    # Set country and year as index\n",
    "    speakers_df.set_index(['Year', \"Country\"], inplace=True)\n",
    "\n",
    "    # import manual total speakers data  \n",
    "    manual_speakers = pd.read_csv(f'../misc_data/manual_{speaker_type}_speakers.csv')\n",
    "    \n",
    "    manual_speakers.set_index('Language', inplace=True)\n",
    "    # Cast col names to ints\n",
    "\n",
    "    # Map the manual_speakers index to language codes\n",
    "    manual_speakers.index = manual_speakers.index.map(name_to_lang_code)\n",
    "    # print(manual_speakers)\n",
    "\n",
    "    years = speakers_df.index.get_level_values(0).unique()\n",
    "\n",
    "    for year in years:\n",
    "        # fetch the global number of speakers per language from manual_speakers\n",
    "        manual_speakers_year = manual_speakers[str(year)]\n",
    "        # print(manual_speakers_year)\n",
    "\n",
    "        # aggregate the global speakers per language from speakers_df \n",
    "        speakers_df_year = speakers_df.loc[year]\n",
    "        agg_speakers_df_year = speakers_df_year.sum(axis=0)\n",
    "        # print(agg_speakers_df_year)\n",
    "\n",
    "        # compute the difference to find missing data\n",
    "        diff = manual_speakers_year - agg_speakers_df_year \n",
    "        # print(diff)\n",
    "\n",
    "        # if we're missing data entirely from that year in the country data, don't fill anything in, otherwise fill in the missing data for the right country\n",
    "\n",
    "        languages = diff.index[diff.index.notnull()]\n",
    "\n",
    "        for lang in languages:\n",
    "            if agg_speakers_df_year[lang] == 0:\n",
    "                print(year)\n",
    "                print(\"agg_speakers_df_year[lang]: \", agg_speakers_df_year[lang])\n",
    "                continue # we're missing all the data, don't fill anything in\n",
    "            else:\n",
    "                # fill in the missing data for the right country\n",
    "                speakers_df.loc[year, lang_code_to_country[lang]][lang] = diff[lang]\n",
    "                # print(\"diff[lang]: \", diff[lang])\n",
    "                # print(\"speakers_df.loc[year, lang_code_to_country[lang]][lang]: \", speakers_df.loc[year, lang_code_to_country[lang]][lang])\n",
    "    finished_dfs.append(speakers_df)\n",
    "\n",
    "if len(finished_dfs) == 1:\n",
    "    l1_df = pd.read_csv('../data/cleaned_l1_speakers.csv')\n",
    "    l1_df.set_index(['Year', \"Country\"], inplace=True)\n",
    "    finished_dfs.append(l1_df)\n",
    "\n",
    "    l2_df = pd.read_csv('../data/cleaned_l2_speakers.csv')\n",
    "    l2_df.set_index(['Year', \"Country\"], inplace=True)\n",
    "    finished_dfs.append(l2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = finished_dfs[0]\n",
    "l1_df = finished_dfs[1]\n",
    "l2_df = finished_dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.reorder_levels([\"Country\", \"Year\"])\n",
    "l1_df = l1_df.reorder_levels([\"Country\", \"Year\"])\n",
    "l2_df = l2_df.reorder_levels([\"Country\", \"Year\"])\n",
    "\n",
    "total_df.loc[[\"Portugal\",  \"Brazil\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in population data to verify that we're not overestimating\n",
    "\n",
    "# this code copied from `streamlined_ratio_model.ipynb`\n",
    "pop_df = pd.read_csv('../raw_data/World_Population_Data.csv', header=2)\n",
    "pop_df = pop_df.drop(columns = [\"Indicator Name\", \"Indicator Code\", \"Country Code\", \"Unnamed: 67\"])\n",
    "pop_df = pop_df.set_index(\"Country Name\")\n",
    "# rename index to Country\n",
    "pop_df.index.names = [\"Country\"]\n",
    "\n",
    "pop_df.columns = pop_df.columns.astype(int)\n",
    "\n",
    "pop_to_lang_country_map = {\"Bahamas, The\": \"Bahamas\", \"Brunei Darussalam\": \"Brunei\", \"Cabo Verde\": \"Cape Verde Islands\", \"Hong Kong SAR, China\": \"Hong Kong\", \"Macao SAR, China\": \"Macao\", \"Congo, Rep.\": \"Congo\", \"Congo, Dem. Rep.\": \"Democratic Republic of the Congo\", \"Cote d'Ivoire\": \"Côte d’Ivoire\", \"Timor-Leste\": \"East Timor\", \"Egypt, Arab Rep.\": \"Egypt\", \"Gambia, The\": \"Gambia\", \"Iran, Islamic Rep.\": \"Iran\", \"Kyrgyz Republic\": \"Kyrgyzstan\", \"Lao PDR\": \"Laos\", \"West Bank and Gaza\": \"Palestine\", 'St. Kitts and Nevis': \"Saint Kitts and Nevis\", \"St. Lucia\": \"Saint Lucia\", \"St. Vincent and the Grenadines\": \"Saint Vincent and the Grenadines\", \"St. Martin (French part)\": \"Saint Martin\", \"Sint Maarten (Dutch part)\": \"Sint Maarten\", \"Slovak Republic\": \"Slovakia\", \"Korea, Rep.\": \"South Korea\", \"Syrian Arab Republic\": \"Syria\", \"Sao Tome and Principe\": \"São Tomé e Príncipe\", \"Turkiye\": \"Turkey\", \"Virgin Islands (U.S.)\": \"U.S. Virgin Islands\", \"Venezuela, RB\": \"Venezuela\", \"Viet Nam\": \"Vietnam\", \"Yemen, Rep.\": \"Yemen\"}\n",
    "\n",
    "# not included\n",
    "# Anguilla, British Indian Ocean Territory, Caribbean Netherlands, Taiwan, Christmas Island, Cocos (Keeling) Islands, Cook Islands, Falkland Islands, French Guiana, Guadaloupe, Guernsey, Martinique, Mayotte, Niue, Norfolk Island, Réunion, Saint Barthélemy, Saint Helena, Saint Helena, Ascension, and Tristan da Cunha, Saint Pierre and Miquelon, Taiwan, Tokelau, Wallis and Futuna, Western Sahara\n",
    "\n",
    "# ISSUES - fixed in the original Ethnologue processing `data_cleaning_notebooks/extract_ethnologue_data.ipynb`\n",
    "# Czechia, it changed named and messed up the data\n",
    "# Eswatini also changed name!!\n",
    "# Vietnam changed from Viet Nam to Vietnam\n",
    "\n",
    "# Rename the countries in the population df to match the language df\n",
    "pop_df.index = pop_df.index.map(lambda x: pop_to_lang_country_map[x] if x in pop_to_lang_country_map else x)\n",
    "\n",
    "\n",
    "pop_df\n",
    "\n",
    "stacked_pop_df = pop_df.stack()\n",
    "stacked_pop_df.index.names = [\"Country\", \"Year\"]\n",
    "stacked_pop_df\n",
    "\n",
    "total_df = total_df.assign(Population=stacked_pop_df)\n",
    "l1_df = l1_df.assign(Population=stacked_pop_df)\n",
    "l2_df = l2_df.assign(Population=stacked_pop_df)\n",
    "\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out all the entries where the population is less than the number of speakers\n",
    "# replace the number of speakers with the population\n",
    "\n",
    "i=0\n",
    "for df, name in zip([total_df, l1_df, l2_df], [\"total\", \"l1\", \"l2\"]):\n",
    "    print(name)\n",
    "\n",
    "    languages = df.columns[:-1] # don't include the population column\n",
    "\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for lang in languages:\n",
    "            if row[lang] > row[\"Population\"] * 1.05 and row[lang] > 100000: # if the number of speakers is more than 10% of the population and the speakers is greater than 100,000\n",
    "                i+=1\n",
    "                print(index, lang, row[lang], row[\"Population\"])\n",
    "                df.loc[index, lang] = row['Population'] * 0.99 # if the number of speakers is more than 5% of the population, replace the number of speakers with 99% of the population\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.loc[\"Portugal\"][\"por\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolate L1 and L2\n",
    "\n",
    "If the proportion of L1 speakers is roughly constant in the years that we have, assume that that was true in the past. \n",
    "\n",
    "Then use total speakers to estimate L2 speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = total_df.columns[:-1]\n",
    "countries = total_df.index.get_level_values(0).unique()\n",
    "\n",
    "num_rows_extrapolated = 0\n",
    "for country in countries:\n",
    "    for lang in langs:\n",
    "        # manually pull in some data for the countries that didn't get scraped\n",
    "        if country==\"Egypt\" and lang==\"arz\":\n",
    "            l1_df.at[(country, 2017), lang] = 69000000\n",
    "        if country==\"Bangladesh\" and lang==\"ben\":\n",
    "            l1_df.at[(country, 2017), lang] = 130000000\n",
    "        if country==\"China\" and lang==\"cmn\":\n",
    "            l1_df.at[(country, 2018), lang] = 907000000\n",
    "        if country==\"Germany\" and lang==\"deu\":\n",
    "            l1_df.at[(country, 2019), lang] = 72300000\n",
    "        if country==\"United Kingdom\" and lang==\"eng\":\n",
    "            l1_df.at[(country, 2009), lang] = 56600000\n",
    "        if country==\"France\" and lang==\"fra\":\n",
    "            l1_df.at[(country, 2020), lang] = 62400000\n",
    "        if country==\"India\" and lang==\"hin\":\n",
    "            l1_df.at[(country, 2009), lang] = 339000000\n",
    "        if country==\"Indonesia\" and lang==\"ind\":\n",
    "            l1_df.at[(country, 2015), lang] = 42800000\n",
    "        if country==\"Japan\" and lang==\"jpn\":\n",
    "            l1_df.at[(country, 2020), lang] = 124000000\n",
    "        if country==\"Portugal\" and lang==\"por\":\n",
    "            l1_df.at[(country, 2014), lang] = 9900000\n",
    "        if country==\"Russian Federation\" and lang==\"rus\":\n",
    "            l1_df.at[(country, 2014), lang] = 119000000\n",
    "        if country==\"Spain\" and lang==\"spa\":\n",
    "            l1_df.at[(country, 2019), lang] = 41900000\n",
    "        if country==\"Pakistan\" and lang==\"urd\":\n",
    "            l1_df.at[(country, 2018), lang] = 15000000\n",
    "\n",
    "\n",
    "        # express the L1 speakers as a percentage of the total population\n",
    "        l1_proportion = l1_df.loc[country][lang] / l1_df.loc[country][\"Population\"]\n",
    "        # print(l1_proportion)\n",
    "\n",
    "        # compute standard deviation\n",
    "        std = l1_proportion.std()\n",
    "        if country in missing_countries:\n",
    "            std = 0 # use the above manually entered data even though it's only one data point\n",
    "        \n",
    "        \n",
    "        # if the standard deviation is less than 5%, we'll assume that the ratio of L1 speakers to total speakers is consistent over time\n",
    "        if not np.isnan(std) and std < 0.05:\n",
    "            print(country, lang, \"std: \", std)\n",
    "            mean_proportion = l1_proportion.mean()\n",
    "\n",
    "            years = l1_df.loc[country].index\n",
    "            print(years)\n",
    "            for year in years:\n",
    "                # find entries where L1 is missing\n",
    "                if l1_df.loc[country, year][lang] == 0 or np.isnan(l1_df.loc[country, year][lang]):\n",
    "                    print(\"L1 missing in \", year)\n",
    "                    # and total is present\n",
    "                    if total_df.loc[country, year][lang] != 0:\n",
    "                        print(\"missing data in \", country, year, lang, l1_df.loc[country, year][lang])\n",
    "                        # fill in the missing L1 data with the population * the mean proportion\n",
    "                        l1_df.at[(country, year), lang] = l1_df.loc[country, year][\"Population\"] * mean_proportion\n",
    "                        # and fill in the L2 data with the total - the L1\n",
    "                        l2_df.at[(country, year), lang] = total_df.loc[country, year][lang] - l1_df.loc[country, year][lang]\n",
    "\n",
    "                        num_rows_extrapolated += 1\n",
    "\n",
    "                        # test that L2 is positive\n",
    "                        if l2_df.loc[country, year][lang] < 0:\n",
    "                            l2_df.at[(country, year), lang] = 0\n",
    "\n",
    "# round the  dataframes to the nearest 1000\n",
    "total_df = total_df.round(-3)\n",
    "l1_df = l1_df.round(-3)\n",
    "l2_df = l2_df.round(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_rows_extrapolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(l1_df.loc[\"Spain\", \"spa\"][2009])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that stuff is filled in\n",
    "\n",
    "if l1_df.loc[\"Spain\", \"spa\"][2009] == np.NaN:\n",
    "    print(\"Yay!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_df.loc[\"Portugal\", \"por\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.loc[\"Bangladesh\", \"ben\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('../data/interpolated_total_speakers.csv')\n",
    "l1_df.to_csv('../data/interpolated_l1_speakers.csv')\n",
    "l2_df.to_csv('../data/interpolated_l2_speakers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
